Observations:

1. Logisitic Regression for single feature input data

Optimum learning rate obtained was 0.0001 for fastest convergence, convergence was slower at 0.00001 whereas did not obtain convergence at 0.001

2. Logisitic Regression for two feature input data

This time, a deeper analysis and experimentation was done on learning rate. Optimum learning rate obtained was 0.008 for fastest convergence, convergence was not obtained at a learning rate of 0.009.

PS: Dataset obtained from https://www.kaggle.com/datasets/ansheemongia/dataset-for-binary-classification/ for two feature binary classification, and from https://github.com/codebasics/py/blob/master/ML/7_logistic_reg/insurance_data.csv for single feature binary classification.